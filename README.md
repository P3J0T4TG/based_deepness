# CitrusDetector - Detecci√≥n de Copas de √Årboles

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![ONNX](https://img.shields.io/badge/ONNX-1.18.0-green.svg)
![YOLOv9](https://img.shields.io/badge/YOLOv9-Detection-orange.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.11.0-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**Sistema de detecci√≥n autom√°tica de copas de √°rboles c√≠tricos basado en YOLOv9 y ONNX Runtime**

Desarrollado por: Pedro Juan Torres Gonz√°lez | z32togop@uco.es | CitriData 

Basado en el desarrollo previo de [PUTVision--DeepNess](https://github.com/PUTvision/qgis-plugin-deepness?tab=readme-ov-file)

[Art√≠culo Original](https://www.sciencedirect.com/science/article/pii/S2352711023001917)

[Modelo onnx](https://chmura.put.poznan.pl/s/A9zdp4mKAATEAGu?opendetails=)

[Caracter√≠sticas](#-caracter√≠sticas) ‚Ä¢ [Instalaci√≥n](#-instalaci√≥n) ‚Ä¢ [Uso](#-uso-r√°pido) ‚Ä¢ [Estructura](#-estructura-del-proyecto) ‚Ä¢ [Notebooks](#-notebooks)

</div>

---

## üìã Descripci√≥n


### üéØ Aplicaciones

- üå≥ Inventario autom√°tico de √°rboles en plantaciones
- üìä An√°lisis de densidad y distribuci√≥n de cultivos
- üó∫Ô∏è Mapeo y geolocalizaci√≥n de parcelas agr√≠colas
- üìà Monitoreo del crecimiento y desarrollo de cultivos
- üîç Inspecci√≥n y control de calidad en campo

---

## ‚ú® Caracter√≠sticas

### üöÄ Caracter√≠sticas T√©cnicas

- **Arquitectura Modular**: Clase base `DeepNessModelProcessor` extensible para diferentes tipos de modelos
- **Optimizado para Producci√≥n**: Inferencia con ONNX Runtime para m√°ximo rendimiento
- **Preprocesamiento Inteligente**: Mantiene aspect ratio con padding centrado
- **NMS Robusto**: Non-Maximum Suppression para eliminar detecciones duplicadas
- **Conversi√≥n de Coordenadas Precisa**: Mapeo correcto entre imagen original y detecciones
- **Visualizaci√≥n Integrada**: Herramientas matplotlib para visualizar resultados
- **Logging Completo**: Sistema de logging para debugging y monitoreo

### üìä Especificaciones del Modelo

| Par√°metro | Valor |
|-----------|-------|
| **Modelo** | YOLOv9 (ONNX) |
| **Input Shape** | `[1, 3, 640, 640]` |
| **Output Shape** | `[1, 5, 8400]` |
| **Formato Input** | RGB normalizado [0-1] |
| **Tipo de Detecci√≥n** | Single-class (Copas de √°rboles) |
| **Confianza por defecto** | 0.5 |
| **NMS Threshold** | 0.4 |

---

## üõ†Ô∏è Instalaci√≥n

### Prerrequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Modelo descargado previamente [aqu√≠](https://chmura.put.poznan.pl/s/A9zdp4mKAATEAGu?opendetails=)

### Instalaci√≥n paso a paso

1. **Clonar el repositorio**
```bash
git clone https://github.com/P3J0T4TG/based_deepness.git
cd based_deepness
```

2. **Crear entorno virtual (recomendado)**
```bash
python -m venv venv-based_deepness
source venv-based_deepness/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

---

## üöÄ Uso R√°pido

### Ejemplo B√°sico

```python
from CitrusDetector import CitrusDetector_vf
import cv2

# 1. Inicializar el detector
detector = CitrusDetector_vf(
    model_path="path/to/model.onnx",
    confidence_threshold=0.5,
    nms_threshold=0.4
)

# 2. Cargar imagen
image = cv2.imread("path/to/citrus_image.jpg")

# 3. Ejecutar detecci√≥n
detections = detector.detect(image)

# 4. Visualizar resultados
detector.visualize_detections(image, detections)
```

### Par√°metros de Configuraci√≥n

```python
detector = CitrusDetector_vf(
    model_path="modelo.onnx",           # Ruta al modelo ONNX
    confidence_threshold=0.5,            # Umbral de confianza (0-1)
    nms_threshold=0.4                    # Umbral NMS para IoU
)
```

### Procesamiento de Resultados

```python
# Las detecciones contienen:
for detection in detections:
    x1, y1, x2, y2 = detection['bbox']  # Coordenadas bounding box
    confidence = detection['confidence']  # Confianza de la detecci√≥n
    class_id = detection['class_id']     # ID de clase
```

---

## üìÅ Estructura del Proyecto

```
based_deepness/
‚îÇ
‚îú‚îÄ‚îÄ CitrusDetector.py              # Clase principal de detecci√≥n
‚îú‚îÄ‚îÄ requirements.txt               # Dependencias del proyecto
‚îú‚îÄ‚îÄ README.md                      # Este archivo
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 1_DeepNess_vf.ipynb       # Desarrollo y explicaci√≥n del modelo
‚îÇ   ‚îî‚îÄ‚îÄ 2_Uso_CitrusDetector.ipynb # Tutorial de uso y ejemplos
‚îÇ
‚îî‚îÄ‚îÄ data/                          # Directorio para datos (modelos/im√°genes)
    ‚îú‚îÄ‚îÄ models/                    # Modelos ONNX
    ‚îî‚îÄ‚îÄ images/                    # Im√°genes de prueba
```

---

## üìì Notebooks

El proyecto incluye dos notebooks interactivos para facilitar el aprendizaje y uso:

### 1Ô∏è‚É£ [1_DeepNess_vf.ipynb](1_DeepNess_vf.ipynb)

**Desarrollo y Arquitectura del Sistema**

- üèóÔ∏è Explicaci√≥n detallada de la clase `DeepNessModelProcessor`
- üîß Implementaci√≥n paso a paso de `CitrusDetector_vf`
- üìê An√°lisis de preprocesamiento y transformaciones de imagen
- üß™ Tests y validaci√≥n del modelo
- üìä An√°lisis de rendimiento

**Ideal para**: Desarrolladores que quieren entender el funcionamiento interno o extender el sistema.

### 2Ô∏è‚É£ [2_Uso_CitrusDetector.ipynb](2_Uso_CitrusDetector.ipynb)

**Tutorial de Uso y Ejemplos Pr√°cticos**

- üéØ Ejemplos de uso b√°sico
- üì∏ Procesamiento de im√°genes individuales
- üîÑ Procesamiento por lotes
- üé® Visualizaci√≥n avanzada de resultados
- üí° Tips y mejores pr√°cticas
- üêõ Troubleshooting com√∫n

**Ideal para**: Usuarios finales que quieren usar el detector en sus proyectos.

---

## üîß Funcionalidades Principales

### Clase `DeepNessModelProcessor`

Clase base gen√©rica para procesamiento de modelos ONNX:

```python
class DeepNessModelProcessor:
    """Procesador base para modelos ONNX"""
    
    def __init__(self, model_path, model_type)
    def _initialize_session()          # Inicializa ONNX Runtime
    def run_inference(preprocessed_image)  # Ejecuta inferencia
```

### Clase `CitrusDetector_vf`

Detector especializado extendido de `DeepNessModelProcessor`:

```python
class CitrusDetector_vf(DeepNessModelProcessor):
    """Detector de c√≠tricos con YOLOv9"""
    
    def preprocess_image(image)        # Preprocesamiento con aspect ratio
    def detect(image)                  # Pipeline completo de detecci√≥n
    def postprocess_detections(output) # NMS y filtrado
    def visualize_detections(image, detections)  # Visualizaci√≥n
```

---

## üìä Pipeline de Detecci√≥n

```mermaid
graph LR
    A[Imagen Original] --> B[Preprocesamiento]
    B --> C[Redimensionar + Padding]
    C --> D[Normalizaci√≥n RGB]
    D --> E[Inferencia ONNX]
    E --> F[Postprocesamiento]
    F --> G[NMS]
    G --> H[Conversi√≥n Coordenadas]
    H --> I[Detecciones Finales]
```

---

## üéØ Preprocesamiento

El sistema implementa un preprocesamiento robusto:

1. **Conversi√≥n de color**: BGR ‚Üí RGB
2. **Redimensionamiento proporcional**: Mantiene aspect ratio
3. **Padding inteligente**: Centra la imagen con padding gris (114)
4. **Normalizaci√≥n**: Valores [0-255] ‚Üí [0-1]
5. **Formato tensor**: HWC ‚Üí CHW
6. **Batch dimension**: (3, 640, 640) ‚Üí (1, 3, 640, 640)

---

## üìà Post-procesamiento

1. **Conversi√≥n de formato**: [1, 5, 8400] ‚Üí [8400, 5]
2. **Filtrado por confianza**: Elimina detecciones con baja confianza
3. **Non-Maximum Suppression (NMS)**: Elimina duplicados
4. **Conversi√≥n de coordenadas**: De espacio 640x640 a imagen original

---

## üîç Detalles T√©cnicos

### Formato de Salida del Modelo

```python
# Output shape: [1, 5, 8400]
# Cada detecci√≥n contiene: [x_center, y_center, width, height, confidence]
# Las coordenadas est√°n en el espacio de entrada (640x640)
```

### Conversi√≥n de Coordenadas

```python
# De coordenadas centradas a esquinas
x1 = (x_center - width/2) / scale - x_offset
y1 = (y_center - height/2) / scale - y_offset
x2 = (x_center + width/2) / scale - x_offset
y2 = (y_center + height/2) / scale - y_offset
```

---

## üé® Visualizaci√≥n

El sistema incluye herramientas de visualizaci√≥n:

```python
detector.visualize_detections(
    image,
    detections,
    figsize=(15, 10),
    show_confidence=True
)
```

Caracter√≠sticas de visualizaci√≥n:
- üü¢ Bounding boxes con color personalizable
- üìä Etiquetas con nivel de confianza
- üìê Informaci√≥n de dimensiones
- üéØ Contador de detecciones

---

## üì¶ Dependencias Principales

| Librer√≠a | Versi√≥n | Prop√≥sito |
|----------|---------|-----------|
| `numpy` | 1.26.4 | Operaciones num√©ricas |
| `opencv-python` | 4.11.0 | Procesamiento de im√°genes |
| `onnxruntime` | 1.17.0 | Inferencia del modelo |
| `matplotlib` | 3.10.3 | Visualizaci√≥n |
| `pillow` | 11.3.0 | Manipulaci√≥n de im√°genes |
| `pandas` | 2.3.1 | An√°lisis de datos |

Ver [requirements.txt](requirements.txt) para lista completa.

---

## üë§ Autor

**Pedro Juan Torres Gonz√°lez**  
CitriData - Tecnolog√≠a para el Sector Citr√≠cola

- üìß Email: [z32togop@uco.es]
- üåê Web: [www.citridata.com]
- üíº LinkedIn: [https://www.linkedin.com/in/pedrojtg/]

---

## üôè Agradecimientos

Sobre todo agradecer a PUTvision por su apoyo a la Ciencia Abierta y el desarrollo de heramientas OpenSource que hacen la investigaci√≥n m√°s f√°cil para aquellos que nos dedicamos a ella.

Si usas parte de este desarrollo o los modelos desarrollados por PUTvision no olvides en citarlos correctamente:

```
@article{ASZKOWSKI2023101495,
title = {Deepness: Deep neural remote sensing plugin for QGIS},
journal = {SoftwareX},
volume = {23},
pages = {101495},
year = {2023},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2023.101495},
url = {https://www.sciencedirect.com/science/article/pii/S2352711023001917},
author = {Przemys≈Çaw Aszkowski and Bartosz Ptak and Marek Kraft and Dominik Pieczy≈Ñski and Pawe≈Ç Drapikowski},
keywords = {QGIS, Deep learning, Remote sensing, Segmentation, Object detection},
}
```
---

## üìö Referencias

- [YOLOv9 Paper](https://arxiv.org/abs/2402.13616)
- [ONNX Documentation](https://onnx.ai/onnx/)
- [OpenCV Documentation](https://docs.opencv.org/)
- [DeepNess Repository](https://github.com/PUTvision/qgis-plugin-deepness/tree/devel)

---

<div align="center">

**‚≠ê Si este proyecto te resulta √∫til, considera darle una estrella ‚≠ê**
</div>
