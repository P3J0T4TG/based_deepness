# CitrusDetector - DetecciÃ³n de Copas de Ãrboles

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![ONNX](https://img.shields.io/badge/ONNX-1.18.0-green.svg)
![YOLOv9](https://img.shields.io/badge/YOLOv9-Detection-orange.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.11.0-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

**Sistema de detecciÃ³n automÃ¡tica de copas de Ã¡rboles cÃ­tricos basado en YOLOv9 y ONNX Runtime**

Desarrollado por: Pedro Juan Torres GonzÃ¡lez | z32togop@uco.es | CitriData 

Basado en el desarrollo previo de PUTVision--DeepNess
https://github.com/PUTvision/qgis-plugin-deepness?tab=readme-ov-file

[ArtÃ­culo Original](https://www.sciencedirect.com/science/article/pii/S2352711023001917)

[Modelo onnx](https://chmura.put.poznan.pl/s/A9zdp4mKAATEAGu?opendetails=)

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢ [InstalaciÃ³n](#-instalaciÃ³n) â€¢ [Uso](#-uso-rÃ¡pido) â€¢ [Estructura](#-estructura-del-proyecto) â€¢ [Notebooks](#-notebooks)

</div>

---

## ğŸ“‹ DescripciÃ³n


### ğŸ¯ Aplicaciones

- ğŸŒ³ Inventario automÃ¡tico de Ã¡rboles en plantaciones
- ğŸ“Š AnÃ¡lisis de densidad y distribuciÃ³n de cultivos
- ğŸ—ºï¸ Mapeo y geolocalizaciÃ³n de parcelas agrÃ­colas
- ğŸ“ˆ Monitoreo del crecimiento y desarrollo de cultivos
- ğŸ” InspecciÃ³n y control de calidad en campo

---

## âœ¨ CaracterÃ­sticas

### ğŸš€ CaracterÃ­sticas TÃ©cnicas

- **Arquitectura Modular**: Clase base `DeepNessModelProcessor` extensible para diferentes tipos de modelos
- **Optimizado para ProducciÃ³n**: Inferencia con ONNX Runtime para mÃ¡ximo rendimiento
- **Preprocesamiento Inteligente**: Mantiene aspect ratio con padding centrado
- **NMS Robusto**: Non-Maximum Suppression para eliminar detecciones duplicadas
- **ConversiÃ³n de Coordenadas Precisa**: Mapeo correcto entre imagen original y detecciones
- **VisualizaciÃ³n Integrada**: Herramientas matplotlib para visualizar resultados
- **Logging Completo**: Sistema de logging para debugging y monitoreo

### ğŸ“Š Especificaciones del Modelo

| ParÃ¡metro | Valor |
|-----------|-------|
| **Modelo** | YOLOv9 (ONNX) |
| **Input Shape** | `[1, 3, 640, 640]` |
| **Output Shape** | `[1, 5, 8400]` |
| **Formato Input** | RGB normalizado [0-1] |
| **Tipo de DetecciÃ³n** | Single-class (Copas de Ã¡rboles) |
| **Confianza por defecto** | 0.5 |
| **NMS Threshold** | 0.4 |

---

## ğŸ› ï¸ InstalaciÃ³n

### Prerrequisitos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)
- Modelo descargado previamente [aquÃ­](https://chmura.put.poznan.pl/s/A9zdp4mKAATEAGu?opendetails=)

### InstalaciÃ³n paso a paso

1. **Clonar el repositorio**
```bash
git clone https://github.com/tuusuario/based_deepness.git
cd based_deepness
```

2. **Crear entorno virtual (recomendado)**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Uso RÃ¡pido

### Ejemplo BÃ¡sico

```python
from CitrusDetector import CitrusDetector_vf
import cv2

# 1. Inicializar el detector
detector = CitrusDetector_vf(
    model_path="path/to/model.onnx",
    confidence_threshold=0.5,
    nms_threshold=0.4
)

# 2. Cargar imagen
image = cv2.imread("path/to/citrus_image.jpg")

# 3. Ejecutar detecciÃ³n
detections = detector.detect(image)

# 4. Visualizar resultados
detector.visualize_detections(image, detections)
```

### ParÃ¡metros de ConfiguraciÃ³n

```python
detector = CitrusDetector_vf(
    model_path="modelo.onnx",           # Ruta al modelo ONNX
    confidence_threshold=0.5,            # Umbral de confianza (0-1)
    nms_threshold=0.4                    # Umbral NMS para IoU
)
```

### Procesamiento de Resultados

```python
# Las detecciones contienen:
for detection in detections:
    x1, y1, x2, y2 = detection['bbox']  # Coordenadas bounding box
    confidence = detection['confidence']  # Confianza de la detecciÃ³n
    class_id = detection['class_id']     # ID de clase
```

---

## ğŸ“ Estructura del Proyecto

```
based_deepness/
â”‚
â”œâ”€â”€ CitrusDetector.py              # Clase principal de detecciÃ³n
â”œâ”€â”€ requirements.txt               # Dependencias del proyecto
â”œâ”€â”€ README.md                      # Este archivo
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1_DeepNess_vf.ipynb       # Desarrollo y explicaciÃ³n del modelo
â”‚   â””â”€â”€ 2_Uso_CitrusDetector.ipynb # Tutorial de uso y ejemplos
â”‚
â””â”€â”€ data/                          # Directorio para datos (modelos/imÃ¡genes)
    â”œâ”€â”€ models/                    # Modelos ONNX
    â””â”€â”€ images/                    # ImÃ¡genes de prueba
```

---

## ğŸ““ Notebooks

El proyecto incluye dos notebooks interactivos para facilitar el aprendizaje y uso:

### 1ï¸âƒ£ [1_DeepNess_vf.ipynb](1_DeepNess_vf.ipynb)

**Desarrollo y Arquitectura del Sistema**

- ğŸ—ï¸ ExplicaciÃ³n detallada de la clase `DeepNessModelProcessor`
- ğŸ”§ ImplementaciÃ³n paso a paso de `CitrusDetector_vf`
- ğŸ“ AnÃ¡lisis de preprocesamiento y transformaciones de imagen
- ğŸ§ª Tests y validaciÃ³n del modelo
- ğŸ“Š AnÃ¡lisis de rendimiento

**Ideal para**: Desarrolladores que quieren entender el funcionamiento interno o extender el sistema.

### 2ï¸âƒ£ [2_Uso_CitrusDetector.ipynb](2_Uso_CitrusDetector.ipynb)

**Tutorial de Uso y Ejemplos PrÃ¡cticos**

- ğŸ¯ Ejemplos de uso bÃ¡sico
- ğŸ“¸ Procesamiento de imÃ¡genes individuales
- ğŸ”„ Procesamiento por lotes
- ğŸ¨ VisualizaciÃ³n avanzada de resultados
- ğŸ’¡ Tips y mejores prÃ¡cticas
- ğŸ› Troubleshooting comÃºn

**Ideal para**: Usuarios finales que quieren usar el detector en sus proyectos.

---

## ğŸ”§ Funcionalidades Principales

### Clase `DeepNessModelProcessor`

Clase base genÃ©rica para procesamiento de modelos ONNX:

```python
class DeepNessModelProcessor:
    """Procesador base para modelos ONNX"""
    
    def __init__(self, model_path, model_type)
    def _initialize_session()          # Inicializa ONNX Runtime
    def run_inference(preprocessed_image)  # Ejecuta inferencia
```

### Clase `CitrusDetector_vf`

Detector especializado extendido de `DeepNessModelProcessor`:

```python
class CitrusDetector_vf(DeepNessModelProcessor):
    """Detector de cÃ­tricos con YOLOv9"""
    
    def preprocess_image(image)        # Preprocesamiento con aspect ratio
    def detect(image)                  # Pipeline completo de detecciÃ³n
    def postprocess_detections(output) # NMS y filtrado
    def visualize_detections(image, detections)  # VisualizaciÃ³n
```

---

## ğŸ“Š Pipeline de DetecciÃ³n

```mermaid
graph LR
    A[Imagen Original] --> B[Preprocesamiento]
    B --> C[Redimensionar + Padding]
    C --> D[NormalizaciÃ³n RGB]
    D --> E[Inferencia ONNX]
    E --> F[Postprocesamiento]
    F --> G[NMS]
    G --> H[ConversiÃ³n Coordenadas]
    H --> I[Detecciones Finales]
```

---

## ğŸ¯ Preprocesamiento

El sistema implementa un preprocesamiento robusto:

1. **ConversiÃ³n de color**: BGR â†’ RGB
2. **Redimensionamiento proporcional**: Mantiene aspect ratio
3. **Padding inteligente**: Centra la imagen con padding gris (114)
4. **NormalizaciÃ³n**: Valores [0-255] â†’ [0-1]
5. **Formato tensor**: HWC â†’ CHW
6. **Batch dimension**: (3, 640, 640) â†’ (1, 3, 640, 640)

---

## ğŸ“ˆ Post-procesamiento

1. **ConversiÃ³n de formato**: [1, 5, 8400] â†’ [8400, 5]
2. **Filtrado por confianza**: Elimina detecciones con baja confianza
3. **Non-Maximum Suppression (NMS)**: Elimina duplicados
4. **ConversiÃ³n de coordenadas**: De espacio 640x640 a imagen original

---

## ğŸ” Detalles TÃ©cnicos

### Formato de Salida del Modelo

```python
# Output shape: [1, 5, 8400]
# Cada detecciÃ³n contiene: [x_center, y_center, width, height, confidence]
# Las coordenadas estÃ¡n en el espacio de entrada (640x640)
```

### ConversiÃ³n de Coordenadas

```python
# De coordenadas centradas a esquinas
x1 = (x_center - width/2) / scale - x_offset
y1 = (y_center - height/2) / scale - y_offset
x2 = (x_center + width/2) / scale - x_offset
y2 = (y_center + height/2) / scale - y_offset
```

---

## ğŸ¨ VisualizaciÃ³n

El sistema incluye herramientas de visualizaciÃ³n:

```python
detector.visualize_detections(
    image,
    detections,
    figsize=(15, 10),
    show_confidence=True
)
```

CaracterÃ­sticas de visualizaciÃ³n:
- ğŸŸ¢ Bounding boxes con color personalizable
- ğŸ“Š Etiquetas con nivel de confianza
- ğŸ“ InformaciÃ³n de dimensiones
- ğŸ¯ Contador de detecciones

---

## ğŸ“¦ Dependencias Principales

| LibrerÃ­a | VersiÃ³n | PropÃ³sito |
|----------|---------|-----------|
| `numpy` | 1.26.4 | Operaciones numÃ©ricas |
| `opencv-python` | 4.11.0 | Procesamiento de imÃ¡genes |
| `onnxruntime` | 1.17.0 | Inferencia del modelo |
| `matplotlib` | 3.10.3 | VisualizaciÃ³n |
| `pillow` | 11.3.0 | ManipulaciÃ³n de imÃ¡genes |
| `pandas` | 2.3.1 | AnÃ¡lisis de datos |

Ver [requirements.txt](requirements.txt) para lista completa.

---

## ğŸ‘¤ Autor

**Pedro Juan Torres GonzÃ¡lez**  
CitriData - TecnologÃ­a para el Sector CitrÃ­cola

- ğŸ“§ Email: [z32togop@uco.es]
- ğŸŒ Web: [www.citridata.com]
- ğŸ’¼ LinkedIn: [https://www.linkedin.com/in/pedrojtg/]

---

## ğŸ™ Agradecimientos

Sobre todo agradecer a PUTvision por su apoyo a la Ciencia Abierta y el desarrollo de heramientas OpenSource que hacen la investigaciÃ³n mÃ¡s fÃ¡cil para aquellos que nos dedicamos a ella.

Si usas parte de este desarrollo o los modelos desarrollados por PUTvision no olvides en citarlos correctamente:

```
@article{ASZKOWSKI2023101495,
title = {Deepness: Deep neural remote sensing plugin for QGIS},
journal = {SoftwareX},
volume = {23},
pages = {101495},
year = {2023},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2023.101495},
url = {https://www.sciencedirect.com/science/article/pii/S2352711023001917},
author = {PrzemysÅ‚aw Aszkowski and Bartosz Ptak and Marek Kraft and Dominik PieczyÅ„ski and PaweÅ‚ Drapikowski},
keywords = {QGIS, Deep learning, Remote sensing, Segmentation, Object detection},
}
```
---

## ğŸ“š Referencias

- [YOLOv9 Paper](https://arxiv.org/abs/2402.13616)
- [ONNX Documentation](https://onnx.ai/onnx/)
- [OpenCV Documentation](https://docs.opencv.org/)
- [DeepNess Repository](https://github.com/PUTvision/qgis-plugin-deepness/tree/devel)

---

<div align="center">

**â­ Si este proyecto te resulta Ãºtil, considera darle una estrella â­**
</div>
